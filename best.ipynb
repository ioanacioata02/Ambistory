{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Adafactor,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATING_OFFSET = 0.5\n",
    "RATING_SCALE = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    model_name: str = \"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\"\n",
    "    train_path: str = \"/kaggle/input/ambistory-raw/train.json\"\n",
    "    dev_path: str = \"/kaggle/input/ambistory-raw/dev.json\"\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    max_length: int = 256\n",
    "    train_batch_size: int = 8\n",
    "    eval_batch_size: int = 64\n",
    "    epochs: int = 10\n",
    "    learning_rate: float = 2e-5\n",
    "    warmup_ratio: float = 0.06\n",
    "    weight_decay: float = 0.0\n",
    "    gradient_accumulation_steps: int = 2\n",
    "\n",
    "    fp16: bool = True\n",
    "    gradient_checkpointing: bool = True\n",
    "\n",
    "    output_model_path: str = \"best_deberta_nli.pt\"\n",
    "    predictions_path: str = \"predictions_deberta_nli.jsonl\"\n",
    "    seed: int = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvironmentManager:\n",
    "    @staticmethod\n",
    "    def set_seed(seed: int = 42):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmbiStoryNliDataset(Dataset):\n",
    "    def __init__(self, json_path: str, tokenizer, max_length: int):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        with open(json_path, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        self.sids = list(self.data.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sid = self.sids[idx]\n",
    "        item = self.data[sid]\n",
    "\n",
    "        pre = item.get(\"precontext\", \"\").strip()\n",
    "        sent = item.get(\"sentence\", \"\").strip()\n",
    "        end = item.get(\"ending\", \"\").strip()\n",
    "\n",
    "        hom = item.get(\"homonym\", \"\").strip()\n",
    "        meaning = item.get(\"judged_meaning\", \"\").strip()\n",
    "        ex_sent = item.get(\"example_sentence\", \"\").strip()\n",
    "\n",
    "        premise = \" \".join(p for p in [pre, sent, end] if p)\n",
    "        hypothesis = (\n",
    "            f'The definition of \"{hom}\" is: \"{meaning}\" '\n",
    "            f'as in the following sentence: \"{ex_sent}\"'\n",
    "        )\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            premise,\n",
    "            hypothesis,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        avg = float(item.get(\"average\", 0.0))\n",
    "        scaled = (avg - RATING_OFFSET) / RATING_SCALE\n",
    "\n",
    "        choices = item.get(\"choices\", [])\n",
    "        choices = list(choices) if isinstance(choices, (list, tuple)) else [choices]\n",
    "        if len(choices) >= 2:\n",
    "            gold_mean = float(np.mean(choices))\n",
    "            gold_stdev = float(np.std(choices, ddof=1))\n",
    "        elif len(choices) == 1:\n",
    "            gold_mean = float(choices[0])\n",
    "            gold_stdev = 0.0\n",
    "        else:\n",
    "            gold_mean = avg\n",
    "            gold_stdev = 0.0\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(scaled, dtype=torch.float),\n",
    "            \"gold_mean\": torch.tensor(gold_mean, dtype=torch.float),\n",
    "            \"gold_stdev\": torch.tensor(gold_stdev, dtype=torch.float),\n",
    "            \"id\": int(sid) if str(sid).isdigit() else sid,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def official_scores_from_stats(\n",
    "    model,\n",
    "    loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    clamp_min: float = RATING_OFFSET,\n",
    "    clamp_max: float = 5.5,\n",
    "    round_to_int: bool = False,\n",
    "):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    gold_means = []\n",
    "    gold_stdevs = []\n",
    "\n",
    "    for batch in loader:\n",
    "        ids = batch[\"input_ids\"].to(device)\n",
    "        mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask)\n",
    "        logits = outputs.logits.squeeze(-1)\n",
    "\n",
    "        p = logits.detach().cpu().numpy()\n",
    "        p = p * RATING_SCALE + RATING_OFFSET\n",
    "        if clamp_min is not None and clamp_max is not None:\n",
    "            p = np.clip(p, clamp_min, clamp_max)\n",
    "\n",
    "        gold_mean = batch[\"gold_mean\"].numpy()\n",
    "        gold_stdev = batch[\"gold_stdev\"].numpy()\n",
    "\n",
    "        if round_to_int:\n",
    "            p = np.rint(p).astype(int)\n",
    "\n",
    "        preds.extend(p.tolist())\n",
    "        gold_means.extend(gold_mean.tolist())\n",
    "        gold_stdevs.extend(gold_stdev.tolist())\n",
    "\n",
    "    corr, _ = spearmanr(preds, gold_means)\n",
    "    corr = float(corr)\n",
    "\n",
    "    correct = 0\n",
    "    total = len(preds)\n",
    "    for pred, m, sd in zip(preds, gold_means, gold_stdevs):\n",
    "        ok = ((m - sd) < pred < (m + sd)) or (abs(m - pred) < 1.0)\n",
    "        correct += int(ok)\n",
    "    acc = correct / total if total else 0.0\n",
    "\n",
    "    return corr, float(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def save_predictions_jsonl(\n",
    "    model,\n",
    "    loader: DataLoader,\n",
    "    out_path: str,\n",
    "    device: torch.device,\n",
    "    clamp_min: float = RATING_OFFSET,\n",
    "    clamp_max: float = 5.5,\n",
    "    round_to_int: bool = True,\n",
    "):\n",
    "    model.eval()\n",
    "    os.makedirs(os.path.dirname(out_path) or \".\", exist_ok=True)\n",
    "\n",
    "    with open(out_path, \"w\") as f:\n",
    "        for batch in loader:\n",
    "            ids = batch[\"input_ids\"].to(device)\n",
    "            mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=ids, attention_mask=mask)\n",
    "            logits = outputs.logits.squeeze(-1)\n",
    "\n",
    "            p = logits.detach().cpu().numpy()\n",
    "            p = p * RATING_SCALE + RATING_OFFSET\n",
    "            if clamp_min is not None and clamp_max is not None:\n",
    "                p = np.clip(p, clamp_min, clamp_max)\n",
    "            if round_to_int:\n",
    "                p = np.rint(p).astype(int)\n",
    "\n",
    "            for sid, pred in zip(batch[\"id\"], p.tolist()):\n",
    "                if isinstance(sid, torch.Tensor):\n",
    "                    sid = sid.item()\n",
    "                rec = {\"id\": sid, \"prediction\": pred}\n",
    "                f.write(json.dumps(rec) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "        self.device = torch.device(cfg.device)\n",
    "        self._prepare_components()\n",
    "\n",
    "        self.best_combined = -1.0\n",
    "        self.best_epoch = -1\n",
    "\n",
    "        self.scaler = GradScaler(\n",
    "            enabled=(self.device.type == \"cuda\" and self.cfg.fp16)\n",
    "        )\n",
    "\n",
    "    def _prepare_components(self):\n",
    "        print(\"Loading tokenizer and datasets...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.cfg.model_name)\n",
    "\n",
    "        self.train_dataset = AmbiStoryNliDataset(\n",
    "            json_path=self.cfg.train_path,\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.cfg.max_length,\n",
    "        )\n",
    "        self.dev_dataset = AmbiStoryNliDataset(\n",
    "            json_path=self.cfg.dev_path,\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.cfg.max_length,\n",
    "        )\n",
    "\n",
    "        self.train_loader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.cfg.train_batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        self.dev_loader = DataLoader(\n",
    "            self.dev_dataset,\n",
    "            batch_size=self.cfg.eval_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        print(\"Loading model...\")\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.cfg.model_name,\n",
    "            num_labels=1,\n",
    "            problem_type=\"regression\",\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "        if self.cfg.gradient_checkpointing:\n",
    "            try:\n",
    "                self.model.gradient_checkpointing_enable(\n",
    "                    gradient_checkpointing_kwargs={\"use_reentrant\": False}\n",
    "                )\n",
    "            except TypeError:\n",
    "                self.model.gradient_checkpointing_enable()\n",
    "\n",
    "        if hasattr(self.model.config, \"use_cache\"):\n",
    "            self.model.config.use_cache = False\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.optimizer = Adafactor(\n",
    "            self.model.parameters(),\n",
    "            lr=self.cfg.learning_rate,\n",
    "            scale_parameter=False,\n",
    "            relative_step=False,\n",
    "            weight_decay=self.cfg.weight_decay,\n",
    "        )\n",
    "\n",
    "        num_update_steps_per_epoch = math.ceil(\n",
    "            len(self.train_loader) / self.cfg.gradient_accumulation_steps\n",
    "        )\n",
    "        num_training_steps = self.cfg.epochs * num_update_steps_per_epoch\n",
    "        num_warmup_steps = int(self.cfg.warmup_ratio * num_training_steps)\n",
    "\n",
    "        self.lr_scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_training_steps,\n",
    "        )\n",
    "\n",
    "    def fit(self):\n",
    "        print(f\"Starting training on {self.device} for {self.cfg.epochs} epochs.\")\n",
    "        self.optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        for epoch in range(self.cfg.epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0.0\n",
    "            step = 0\n",
    "\n",
    "            for batch_idx, batch in enumerate(self.train_loader):\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                labels = batch[\"labels\"].to(self.device)\n",
    "\n",
    "                with autocast(\n",
    "                    device_type=self.device.type,\n",
    "                    enabled=(self.device.type == \"cuda\" and self.cfg.fp16),\n",
    "                ):\n",
    "                    outputs = self.model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels,\n",
    "                    )\n",
    "                    loss = outputs.loss\n",
    "                    loss = loss / self.cfg.gradient_accumulation_steps\n",
    "\n",
    "                self.scaler.scale(loss).backward()\n",
    "                total_loss += loss.item()\n",
    "                step += 1\n",
    "\n",
    "                if step % self.cfg.gradient_accumulation_steps == 0:\n",
    "                    self.scaler.step(self.optimizer)\n",
    "                    self.scaler.update()\n",
    "                    self.optimizer.zero_grad(set_to_none=True)\n",
    "                    self.lr_scheduler.step()\n",
    "\n",
    "            avg_loss = total_loss / max(1, step)\n",
    "            print(f\"Epoch {epoch+1}/{self.cfg.epochs} - train loss: {avg_loss:.4f}\")\n",
    "\n",
    "            corr, acc = official_scores_from_stats(\n",
    "                self.model,\n",
    "                self.dev_loader,\n",
    "                device=self.device,\n",
    "                clamp_min=RATING_OFFSET,\n",
    "                clamp_max=5.5,\n",
    "                round_to_int=False,\n",
    "            )\n",
    "            combined = 0.5 * (corr + acc)\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - dev Spearman: {corr:.4f}, \"\n",
    "                f\"dev Acc@SD/1: {acc:.4f}, combined: {combined:.4f}\"\n",
    "            )\n",
    "\n",
    "            if combined > self.best_combined:\n",
    "                self.best_combined = combined\n",
    "                self.best_epoch = epoch + 1\n",
    "                torch.save(self.model.state_dict(), self.cfg.output_model_path)\n",
    "                print(\n",
    "                    f\"New best model saved to {self.cfg.output_model_path} \"\n",
    "                    f\"(epoch {self.best_epoch}, combined={self.best_combined:.4f})\"\n",
    "                )\n",
    "\n",
    "        print(\"Training finished.\")\n",
    "        print(f\"Best epoch: {self.best_epoch}, best combined: {self.best_combined:.4f}\")\n",
    "\n",
    "    def load_best_and_predict(self):\n",
    "        if os.path.exists(self.cfg.output_model_path):\n",
    "            self.model.load_state_dict(\n",
    "                torch.load(self.cfg.output_model_path, map_location=self.device)\n",
    "            )\n",
    "            print(\n",
    "                f\"Loaded best model from {self.cfg.output_model_path} \"\n",
    "                f\"(epoch {self.best_epoch}, combined={self.best_combined:.4f})\"\n",
    "            )\n",
    "        else:\n",
    "            print(\"Best model file not found, using current model weights.\")\n",
    "\n",
    "        save_predictions_jsonl(\n",
    "            model=self.model,\n",
    "            loader=self.dev_loader,\n",
    "            out_path=self.cfg.predictions_path,\n",
    "            device=self.device,\n",
    "            clamp_min=RATING_OFFSET,\n",
    "            clamp_max=5.5,\n",
    "            round_to_int=True,\n",
    "        )\n",
    "        print(f\"Dev predictions saved to {self.cfg.predictions_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    EnvironmentManager.set_seed(cfg.seed)\n",
    "\n",
    "    print(\"Config:\")\n",
    "    print(cfg)\n",
    "\n",
    "    trainer = Trainer(cfg)\n",
    "    trainer.fit()\n",
    "    trainer.load_best_and_predict()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9150398,
     "sourceId": 14332434,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
